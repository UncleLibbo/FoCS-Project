{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations of Computer Science Project \n",
    "\n",
    "Professor: Gianluca Della Vedova\n",
    "\n",
    "Project made by Liborio Adriano Mastrolia\n",
    "\n",
    "Badge Number: 901970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to work on the [Dogs adoptions](https://drive.google.com/file/d/1wQsA0oB6wwYlnkvvcyBCmLk7QmgVWNax/view?usp=sharing) dataset. \n",
    "\n",
    "It contains three files:\n",
    "*  `dogs.csv`, shortly *dogs*\n",
    "*  `dogTravel.csv`, shortly *travels*\n",
    "*  `NST-EST2021-POP.csv`\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com).\n",
    "1.    At most 3 students can be in each group. You must create the groups by yourself.\n",
    "1.    You do not have to send me the project *before* the discussion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to import Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import difflib "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, to visualize data better, we need to set some options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to read the files `dogs.csv`, `dogTravel.csv` and `NST-EST2021-POP.csv` and from the dogs adoptions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = pd.read_csv(r\"C:\\Users\\mastr\\OneDrive\\Desktop\\Università\\Foundations of Computer Science\\Project\\Dataset\\dogs.csv\")\n",
    "\n",
    "dogTravel = pd.read_csv(r\"C:\\Users\\mastr\\OneDrive\\Desktop\\Università\\Foundations of Computer Science\\Project\\Dataset\\dogTravel.csv\")\n",
    "\n",
    "Population = pd.read_csv(r\"C:\\Users\\mastr\\OneDrive\\Desktop\\Università\\Foundations of Computer Science\\Project\\Dataset\\NST-EST2021-POP.csv\", names=['State','Population'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put 'r' before string due to the following error: \n",
    "\n",
    "- SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n",
    "\n",
    "In this way, the path gets converted to a raw string from a normal string and can be read without problems. Moreover, since the last csv didn't have any header row, we add one directly in Python, without any need to alter the original file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reference, we will now count the total amount of rows and columns on each of the three datasets, in order to understand the dimension of each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogTravel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read each dataset, with the command 'head' which will show the first 5 rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogTravel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract all dogs with status that is not *adoptable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_adoptable_dogs = dogs[dogs['status'] != 'adoptable']\n",
    "\n",
    "not_adoptable_dogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each (primary) breed, determine the number of dogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, we need to check if there is any missing values (NaN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['breed_primary'].isnull().values.any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no 'Nan' values, we can determine the number of dogs for each primary breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_breed_dogs = dogs.groupby('breed_primary').count()['id']\n",
    "\n",
    "primary_breed_dogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 'count' method counts the number of non-missing rows for each column, it is better to choose a column: that's why we referred to column 'id'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each (primary) breed, determine the ratio between the number of dogs of `Mixed Breed` and those not of Mixed Breed. Hint: look at the `secondary_breed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dogs = dogs.groupby('breed_primary')\n",
    "\n",
    "mixed_breed_count = grouped_dogs['breed_secondary'].apply(lambda x: (x == 'Mixed Breed').sum())\n",
    "not_mixed_count = grouped_dogs.size() - mixed_breed_count\n",
    "\n",
    "ratio = mixed_breed_count / not_mixed_count\n",
    "\n",
    "result_mixed_breed = pd.DataFrame({\n",
    "    'Primary Breed': grouped_dogs.groups.keys(),\n",
    "    'Mixed Breed Count': mixed_breed_count,\n",
    "    'Not Mixed Breed Count': not_mixed_count,\n",
    "    'Ratio': round(ratio, 3)\n",
    "}).set_index('Primary Breed')\n",
    "\n",
    "result_mixed_breed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For each (primary) breed, determine the earliest and the latest `posted` timestamp."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, in the column 'posted' there are a few values which are not datetime, but city names; we need to remove these values by dropping them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['posted'] = pd.to_datetime(dogs['posted'], errors = 'coerce')\n",
    "\n",
    "dogs = dogs.dropna(subset=['posted'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting errors = 'coerce' means that invalid parsing will be set as NaT (Not a Time), and then it will be dropped with 'dropna' method. This will always be useful for task number 6. We can now move on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest = dogs.groupby('breed_primary')['posted'].min()\n",
    "latest = dogs.groupby('breed_primary')['posted'].max()\n",
    "\n",
    "timestamp = pd.DataFrame({\n",
    "    'Primary Breed': grouped_dogs.groups.keys(),\n",
    "    'Earliest Timestamp': earliest,\n",
    "    'Latest Timestamp': latest\n",
    "}).set_index('Primary Breed')\n",
    "\n",
    "timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For each state, compute the sex imbalance, that is the difference between male and female dogs. In which state this imbalance is largest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's check for unique values on 'contact_state', since it will be the column we will use in the groupby operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['contact_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then perform task 5, since all values can be considered valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_states = dogs.groupby('contact_state')\n",
    "\n",
    "sex_imbalance = grouped_states['sex'].apply(lambda x: (x == 'Male').sum() - (x == 'Female').sum())\n",
    "\n",
    "state_with_largest_imbalance = sex_imbalance.idxmax()\n",
    "\n",
    "result_sex_imbalance = pd.DataFrame({\n",
    "    'State': grouped_states.groups.keys(),\n",
    "    'Sex Imbalance': sex_imbalance\n",
    "}).set_index('State')\n",
    "\n",
    "result_sex_imbalance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After displaying all the data regarding the sex imbalance, we can find the state with the largest sex imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"State with largest sex imbalance is\", state_with_largest_imbalance, \"with a sex imbalance of\", result_sex_imbalance['Sex Imbalance'].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For each pair (age, size), determine the average duration of the stay and the average cost of stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_age_size = dogs.groupby(['age', 'size'])\n",
    "\n",
    "avg_duration = grouped_age_size['stay_duration'].mean()\n",
    "avg_cost = grouped_age_size['stay_cost'].mean()\n",
    "\n",
    "result_age_size = pd.DataFrame({\n",
    "    'Age': [pair[0] for pair in grouped_age_size.groups.keys()],\n",
    "    'Size': [pair[1] for pair in grouped_age_size.groups.keys()],\n",
    "    'Average Duration of Stay': avg_duration,\n",
    "    'Average Cost of Stay': avg_cost\n",
    "}).set_index(['Age', 'Size'])\n",
    "\n",
    "result_age_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Find the dogs involved in at least 3 travels. Also list the breed of those dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_travels = pd.merge(dogs, dogTravel, on = 'id', how='inner')\n",
    "\n",
    "dogs_with_3_or_more_travels = dogs_travels.groupby('id').filter(lambda x: len(x) >= 3)\n",
    "\n",
    "dogs_with_3_or_more_travels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds_of_dogs_with_3_or_more_travels = dogs_with_3_or_more_travels['breed_primary'].unique()\n",
    "\n",
    "breeds_of_dogs_with_3_or_more_travels.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fix the `travels` table so that the correct state is computed from  the `manual` and the `found` fields. If `manual` is not missing, then it overrides what is stored in `found`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogTravel['state'] = dogTravel.apply(lambda row: row['manual'] if pd.notnull(row['manual']) else row['found'], axis=1)\n",
    "\n",
    "dogTravel.drop(['found', 'manual'], axis=1, inplace=True)\n",
    "\n",
    "dogTravel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. For each state, compute the ratio between the number of travels and the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels_by_state = dogTravel.groupby('state').size().reset_index(name='Travels')\n",
    "\n",
    "state_population = pd.merge(travels_by_state, Population, left_on='state', right_on='State', how='inner')\n",
    "\n",
    "state_population['Ratio'] = state_population['Travels'] / state_population['Population'].str.replace('.', '').astype(int)\n",
    "\n",
    "state_population"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. For each dog, compute the number of days from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['posted'] = pd.to_datetime(dogs['posted'], format='ISO8601')\n",
    "\n",
    "dogs['accessed'] = pd.to_datetime(dogs['accessed']).dt.tz_localize('UTC')\n",
    "\n",
    "dogs['days_since_posted'] = (dogs['accessed'] - dogs['posted']).dt.days\n",
    "\n",
    "dogs_dates_days = pd.DataFrame({\n",
    "    'id': dogs['id'].keys(),\n",
    "    'posted': dogs['posted'],\n",
    "    'accessed': dogs['accessed'],\n",
    "    'days_since_posted': dogs['days_since_posted'].apply(lambda x: 0 if x < 0 else x)\n",
    "}).set_index('id')\n",
    "\n",
    "dogs_dates_days"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Partition the dogs according to the number of weeks from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we can reuse the same code from previous task, taking into accounting the 'weeks_since_posted' rather than the 'days_since_posted':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['weeks_since_posted'] = (dogs['days_since_posted'] // 7)\n",
    "\n",
    "dogs_dates_weeks = pd.DataFrame({\n",
    "    'id': dogs['id'].keys(),\n",
    "    'posted': dogs['posted'],\n",
    "    'accessed': dogs['accessed'],\n",
    "    'weeks_since_posted': dogs['weeks_since_posted'].apply(lambda x: 0 if x < 0 else x)\n",
    "}).set_index('id')\n",
    "\n",
    "dogs_dates_weeks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Find for duplicates in the `dogs` dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we must check if any dogs['description'] are empty: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['description'].any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fill the empty rows in the 'dogs' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['description'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start performing data-related checks. Let's check if there are any rows in the dataset which share all the informations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullDuplicateRows = dogs.duplicated()\n",
    "\n",
    "FullDuplicateRows.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are not duplicate rows which share all data, we can now perform another check before performing task number 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DuplicateRows = dogs.duplicated(subset=['sex','breed_primary','breed_secondary', 'breed_mixed', 'breed_unknown', 'description'])\n",
    "\n",
    "DuplicateRows.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many rows this dataset has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DuplicateRows.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are rows which share sex, all the breeds and the entire description, we can remove them from the 'dogs' dataset; to do this, we will use store these rows in another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dogs = dogs.drop_duplicates(subset=['sex','breed_primary','breed_secondary', 'breed_mixed', 'breed_unknown', 'description'], keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these steps, let's perform task 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the description column by removing punctuation and converting to lowercase\n",
    "cleaned_dogs['clean_description'] = cleaned_dogs['description'].str.replace('[^\\w\\s]', '').str.lower()\n",
    "\n",
    "# Sort the dataframe by the 'clean_description' column\n",
    "cleaned_dogs.sort_values('clean_description', inplace=True, ignore_index=False)\n",
    "\n",
    "# Define a function to calculate the similarity between two strings\n",
    "def compute_similarity(input_string, reference_string):\n",
    "    if pd.isnull(input_string) or pd.isnull(reference_string) or input_string == \"\" or reference_string == \"\":\n",
    "        return 0\n",
    "    diff = difflib.ndiff(list(input_string), list(reference_string))\n",
    "    diff_count = sum(1 for line in diff if line.startswith(\"-\"))\n",
    "    return 1 - (diff_count / len(input_string))\n",
    "\n",
    "# Initialize an empty list to store the duplicate pairs\n",
    "duplicate_pairs = []\n",
    "\n",
    "# Iterate over the dataframe to compare adjacent rows\n",
    "for i in range(len(cleaned_dogs) - 1):\n",
    "    current_row = cleaned_dogs.iloc[i]\n",
    "    next_row = cleaned_dogs.iloc[i + 1]\n",
    "    \n",
    "    if (current_row['breed_primary'] == next_row['breed_primary'] and\n",
    "        current_row['breed_secondary'] == next_row['breed_secondary'] and\n",
    "        current_row['breed_mixed'] == next_row['breed_mixed'] and\n",
    "        current_row['breed_unknown'] == next_row['breed_unknown'] and\n",
    "        current_row['sex'] == next_row['sex']):\n",
    "        \n",
    "        similarity = compute_similarity(current_row['clean_description'], next_row['clean_description'])\n",
    "        if similarity >= 0.9:  # Adjust the similarity threshold as needed\n",
    "            duplicate_pairs.append((current_row['id'], next_row['id']))\n",
    "\n",
    "# Create a DataFrame to store the duplicate pairs\n",
    "duplicate_pairs_df = pd.DataFrame(duplicate_pairs, columns=['Duplicate ID 1', 'Duplicate ID 2'])\n",
    "\n",
    "# Print the duplicate pairs DataFrame\n",
    "print(duplicate_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = pd.merge(duplicate_pairs_df, cleaned_dogs, left_on='Duplicate ID 1', right_on='id', suffixes=('', '_dup1'))\n",
    "duplicate_rows = pd.merge(duplicate_rows, cleaned_dogs, left_on='Duplicate ID 2', right_on='id', suffixes=('_dup1', '_dup2'))\n",
    "\n",
    "columns_to_view = ['sex_dup1', 'breed_primary_dup1', 'breed_secondary_dup1', 'breed_mixed_dup1', 'breed_unknown_dup1', 'clean_description_dup1',\n",
    "                   'sex_dup2', 'breed_primary_dup2', 'breed_secondary_dup2', 'breed_mixed_dup2', 'breed_unknown_dup2', 'clean_description_dup2']\n",
    "\n",
    "duplicate_rows = duplicate_rows[columns_to_view].rename(columns={\n",
    "    'sex_dup1': 'Sex Duplicate 1',\n",
    "    'breed_primary_dup1': 'Breed Primary Duplicate 1',\n",
    "    'breed_secondary_dup1': 'Breed Secondary Duplicate 1',\n",
    "    'breed_mixed_dup1': 'Breed Mixed Duplicate 1',\n",
    "    'breed_unknown_dup1': 'Breed Unknown Duplicate 1',\n",
    "    'clean_description_dup1': 'Clean Description Duplicate 1',\n",
    "    'sex_dup2': 'Sex Duplicate 2',\n",
    "    'breed_primary_dup2': 'Breed Primary Duplicate 2',\n",
    "    'breed_secondary_dup2': 'Breed Secondary Duplicate 2',\n",
    "    'breed_mixed_dup2': 'Breed Mixed Duplicate 2',\n",
    "    'breed_unknown_dup2': 'Breed Unknown Duplicate 2',\n",
    "    'clean_description_dup2': 'Clean Description Duplicate 2'\n",
    "})\n",
    "\n",
    "duplicate_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FoCS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
